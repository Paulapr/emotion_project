{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import subprocess, sys\n",
    "import time\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.fftpack import fft, ifft\n",
    "from skimage import util\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Conectar muse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "En terminal:\n",
    "    - $ muselsl list                       --> Detectar Muse\n",
    "    - $ muselsl stream --name MUSE-96E2    --> Comenzar stream\n",
    "    - $ muselsl view --version 2           --> Ver registro, comprobar buena señal, sin artefactos\n",
    "    - $ muselsl record --duration 900      --> Comenzar a grabar. Duracion en segundos\n",
    "    \n",
    "    - Se guardará un archivo csv con el registro: timestamps, canal1, canal2, canal3, canal4\n",
    "    - Hay que abrir el registro con excel y volverlo a guardar como csv (problema con timestamps)\n",
    "    - Archivo: 'registro_eeg.csv'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualización de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lista con la imágenes o imágenes a visualizar\n",
    "list_pictures = ([f for f in listdir('pics_to_predict') if isfile(join('pics_to_predict', f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(list_pictures)\n",
    "orden = list_pictures    # orden en que han aparecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pics (lista):\n",
    "    pic_time= {}\n",
    "    for p in lista:\n",
    "        opener =\"open\" if sys.platform == \"darwin\" else \"xdg-open\"\n",
    "        subprocess.call([opener, p])\n",
    "        timestamp1 = int(round(time.time() * 1000))\n",
    "        time.sleep(10)                                                   # tiempo que está la foto\n",
    "        subprocess.call([opener, 'black-screen.png'])\n",
    "        time.sleep(2)                                                    #tiempo pantalla negra  \n",
    "        timestamp2 = int(round(time.time() * 1000))                              \n",
    "        pic_time.update({p:(timestamp1,timestamp2)})\n",
    "    pic_time_df = pd.DataFrame(list(pic_time.items()), columns=['Picture', 'timestamps'])\n",
    "    pic_time_df = pic_time_df.join(pd.DataFrame(pic_time_df['timestamps'].values.tolist(), columns=['start_time', 'end_time']))\n",
    "    pic_time_df = pic_time_df.drop(['timestamps'], axis = 1)\n",
    "    return pic_time_df     \n",
    "\n",
    "pic_time_df = visualize_pics(list_pictures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Asignar a cada dato EEG la imagen a la que corresponde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eeg_pic(pic, eeg):\n",
    "    eeg.drop(['Right AUX'], axis=1, inplace=True)\n",
    "    eeg['image']='pic' \n",
    "    for row in pic.iterrows():\n",
    "        eeg.loc[(eeg['timestamps']> row[1].start_time) & \n",
    "                (eeg['timestamps'] < row[1].end_time), 'image'] = row[1].Picture\n",
    "    pic_eeg = eeg[eeg.image != 'pic']\n",
    "    pic_eeg.to_csv('pic_egg.csv',index=False)\n",
    "    return pic_eeg\n",
    "\n",
    "registro_eeg = pd.read_csv('registro_pred.csv')     # el registro de Muse después de abrir en excel        \n",
    "pic_eeg = eeg_pic(pic_time_df, registro_eeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Procesar la señal EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado\n",
    "\n",
    "def butter_bandpass(lowcut = 1, highcut = 49, fs = 256, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data):\n",
    "    b, a = butter_bandpass(lowcut = 1, highcut = 49, fs = 256, order=5)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_cols(df):\n",
    "    df['af7_filter'] = butter_bandpass_filter(df.AF7)\n",
    "    df['af8_filter'] = butter_bandpass_filter(df.AF8)\n",
    "    df['tp9_filter'] = butter_bandpass_filter(df.TP9)\n",
    "    df['tp10_filter'] = butter_bandpass_filter(df.TP10)\n",
    "    eeg_filt = df[['image','timestamps','af7_filter','af8_filter','tp9_filter','tp10_filter']]\n",
    "    return eeg_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (butter_cols(pic_eeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs\n",
    "\n",
    "def epochs(sample):\n",
    "    epochs = util.view_as_windows(sample, window_shape=(512,), step=256)\n",
    "    win = np.hanning(512 + 1)[:-1]\n",
    "    epochs = epochs * win\n",
    "    df_epochs = (pd.DataFrame(epochs.T))\n",
    "    df_epochs.columns = ['Win_1','Win_2','Win_3','Win_4','Win_5','Win_6','Win_7','Win_8','Win_9']\n",
    "    return df_epochs\n",
    "\n",
    "def sep_pics(df):\n",
    "    images = list(df.image.unique())\n",
    "    cols = ['af7_filter','af8_filter','tp9_filter','tp10_filter']\n",
    "    pictures = []\n",
    "    \n",
    "    for pic in images:\n",
    "        pic = pic.replace('.bmp','')\n",
    "        pictures.append(pic)\n",
    "        \n",
    "    dict_pictures = {}\n",
    "    for pic in images:\n",
    "        dict_pictures[pic] = (((df[(df['image'] == pic)])[10:2571]).reset_index()).drop(['image','index'], axis = 1)\n",
    "    \n",
    "    dict_pic_epoch = {}\n",
    "\n",
    "    for pic in images:\n",
    "        for col in cols:\n",
    "            sample = ((dict_pictures[pic])[col]).values\n",
    "            dict_pic_epoch[pic+\": \"+col] = epochs(sample)\n",
    "    \n",
    "    return dict_pic_epoch, pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pic_epoch = sep_pics(df)[0]\n",
    "pictures = sep_pics(df)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT\n",
    "\n",
    "def fft_win (to_fft, n, fs):\n",
    "    win_fft = np.abs(np.fft.fft(to_fft, n=n)[:fs // 2])\n",
    "    return win_fft\n",
    "\n",
    "def apply_fft(dict_pic_epoch):\n",
    "    todas_keys = list(dict_pic_epoch.keys())  \n",
    "    windows = ['Win_1','Win_2','Win_3','Win_4','Win_5','Win_6','Win_7','Win_8','Win_9']                                \n",
    "    data_fft_dict = {}\n",
    "    for key in todas_keys:\n",
    "        for win in windows:\n",
    "            to_fft = ((dict_pic_epoch[key])[win]).values\n",
    "            data_fft_dict[key+\": \"+win] = fft_win(to_fft, 8, 256)\n",
    "    data_fft = pd.DataFrame.from_dict(data_fft_dict).T\n",
    "    return data_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fft = apply_fft(dict_pic_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Crear el dataframe final para que entre al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_model(data_fft, pictures):\n",
    "    name_columns = []\n",
    "    chanels = ['AF7','AF8','TP9','TP10']\n",
    "    windows = ['W1','W2','W3','W4','W5','W6','W7','W8','W9']\n",
    "    fft_bins = ['bin1','bin2','bin3','bin4','bin5','bin6','bin7','bin8']\n",
    "    for chanel in chanels:\n",
    "        for window in windows:\n",
    "            for bins in fft_bins:\n",
    "                name_columns.append(('{}'+'-'+'{}'+'-'+'{}').format(chanel, window, bins)) \n",
    "    df_model = pd.DataFrame (data=None, index = pictures, columns=name_columns)\n",
    "    images_cols = []\n",
    "    images_e = []\n",
    "    for i in range(len(pictures)):\n",
    "        images_cols.append(np.array(data_fft.iloc[i*36:(i+1)*36]))\n",
    "    for j in range(len(images_cols)): \n",
    "        for array in images_cols[j]:\n",
    "            for e in array:\n",
    "                images_e.append(e)\n",
    "    for i in range(len(pictures)):\n",
    "        df_model.iloc[i] = images_e[i*288:(i+1)*288]\n",
    "    df_model.to_csv('pics_eeg_process.csv', index= True)\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(df_model), columns=[df_model.columns], index = df_model.index )\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_to_model(data_fft, pictures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Meter al modelo para ver la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X):\n",
    "    dectree_model = pickle.load(open('dectree_model.sav', 'rb'))\n",
    "    ynew1 = dectree_model.predict(X)\n",
    "    for i in range(len(X)):\n",
    "        print(\"Predicted by decision tree for {} order -> Valencia: {:.2f}, Arousal: {:.2f}\".format(i+1, ynew1[i][0],ynew1[i][1]))\n",
    "    forest_model = pickle.load(open('forest_model.sav', 'rb'))\n",
    "    ynew2 = forest_model.predict(X)\n",
    "    for i in range(len(X)):\n",
    "        print(\"Predicted by random forest for {} order-> Valencia: {:.2f}, Arousal: {:.2f}\".format(i+1, ynew2[i][0],ynew2[i][1]))\n",
    "\n",
    "def prediction2(X):\n",
    "    dectree_model = pickle.load(open('dectree_model.sav', 'rb'))\n",
    "    y_dectree = dectree_model.predict(X)\n",
    "    forest_model = pickle.load(open('forest_model.sav', 'rb'))\n",
    "    y_forest = forest_model.predict(X)\n",
    "    return y_forest , y_dectree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(X)\n",
    "y_forest = prediction2(X)[0]\n",
    "y_dectree = prediction2(X)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizar las predicciones obtenidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_df(y_forest, y_dectree, orden):\n",
    "    cols = ['Picture', 'Forest valence', 'Forest Arousal','Dec.Tree valence', 'Dec.Tree Arousal']\n",
    "    predictions = pd.DataFrame()\n",
    "    predictions['Picture'] = orden\n",
    "    predictions['Forest Valence'] = y_forest[:,0]\n",
    "    predictions['Dec.Tree Valence'] = y_dectree[:,0]\n",
    "    predictions['Forest Arousal'] = y_forest[:,1]\n",
    "    predictions['Dec.Tree Arousal'] = y_dectree[:,1]\n",
    "    imagenes = []\n",
    "    for row in predictions['Picture']:\n",
    "        row = row.replace('.jpg','')\n",
    "        imagenes.append(row)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot1 (predictions):\n",
    "    fig = plt.figure(figsize= (8,8))\n",
    "    plt.scatter(predictions['Forest Valence'],predictions['Forest Arousal'], label = 'Random Forest', s=100, alpha = 0.5)\n",
    "    plt.scatter(predictions['Dec.Tree Valence'],predictions['Dec.Tree Arousal'], label = 'Decision Tree', s=100, alpha = 0.5)\n",
    "    plt.xlim([0, 100])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend(fontsize = 15)\n",
    "    plt.xlabel('Valencia', fontsize = 15)\n",
    "    plt.ylabel('Arousal', fontsize = 15)\n",
    "    fig.savefig('forestvsdectree.png')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2 (predictions):\n",
    "    fig, ax = plt.subplots(figsize = (8,8))\n",
    "    ax.scatter(predictions['Forest Valence'],predictions['Forest Arousal'], s=100, alpha = 0.5)\n",
    "    plt.xlim([0, 100])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.xlabel('Valencia')\n",
    "    plt.ylabel('Arousal')\n",
    "    for i, txt in enumerate (imagenes):\n",
    "        ax.annotate(txt, (predictions['Forest Valence'][i],predictions['Forest Arousal'][i]), fontsize=15)\n",
    "    fig.savefig('forest_pred.png')\n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
